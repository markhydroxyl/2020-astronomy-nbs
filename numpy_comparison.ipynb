{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison of vanilla Python vs `numpy`\n",
    "\n",
    "Below, a series of experiments are run to demonstrate the difference in speed between Python and numpy. The comparisons will be on the following categories:\n",
    "\n",
    "- Basic Tests\n",
    "  - generating an array\n",
    "  - summing up the elements of an array\n",
    "  - taking the average of the elements of an array\n",
    "- Computing Non-trivial Functions\n",
    "  - sorting the elements of an array\n",
    "  - computing the standard deviation of the elements of an array\n",
    "  - computing the sine of every element in the array\n",
    "  - computing the exponential of every element in the array\n",
    "- Manipulating Multiple Arrays\n",
    "  - computing element-wise sum over two arrays\n",
    "  - computing element-wise multiplication over two arrays\n",
    "  - taking the dot product of two arrays\n",
    "\n",
    "To conduct these tests, three sets of functions will be used:\n",
    "\n",
    "- `naive`: a naïve approach, using vanilla Python lists and `for` loops\n",
    "- `compr`: using Python __list comprehension__, a very useful (and optimized) version of Python's basic `for` loops, and other built-in functions (that are also optimized)\n",
    "- `numpy`: using the `numpy` library and its versatile set of functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ARRAY_SIZE = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_naive(fill=1, size=ARRAY_SIZE):\n",
    "    naive_list = []\n",
    "    for i in range(size):\n",
    "        naive_list.append(fill)\n",
    "    return naive_list\n",
    "\n",
    "def generate_compr(fill=1, size=ARRAY_SIZE):\n",
    "    compr_list = [fill] * size\n",
    "    return compr_list\n",
    "\n",
    "def generate_numpy(fill=1, size=ARRAY_SIZE):\n",
    "    numpy_arr = np.full((size,), fill)\n",
    "    return numpy_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_rand_naive(size=ARRAY_SIZE):\n",
    "    naive_list = []\n",
    "    for i in range(size):\n",
    "        naive_list.append(random.random())\n",
    "    return naive_list\n",
    "\n",
    "def generate_rand_compr(size=ARRAY_SIZE):\n",
    "    compr_list = [random.random() for i in range(size)]\n",
    "    return compr_list\n",
    "\n",
    "def generate_rand_numpy(size=ARRAY_SIZE):\n",
    "    numpy_arr = np.random.rand(size)\n",
    "    return numpy_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "py_rand = generate_rand_compr()\n",
    "np_rand = np.array(py_rand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Generating via naive for loop, filled with 1, size 10000\n797 µs ± 8.54 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\nGenerating via list comprehension, filled with 1, size 10000\n24.4 µs ± 493 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\nGenerating via numpy.array(), filled with 1, size 10000\n7.99 µs ± 158 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
    }
   ],
   "source": [
    "print('Generating via naive for loop, filled with 1, size', ARRAY_SIZE)\n",
    "%timeit generate_naive()\n",
    "print('Generating via list comprehension, filled with 1, size', ARRAY_SIZE)\n",
    "%timeit generate_compr()\n",
    "print('Generating via numpy.array(), filled with 1, size', ARRAY_SIZE)\n",
    "%timeit generate_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Generating via naive for loop, filled with random values, size 10000\n1.96 ms ± 80.9 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\nGenerating via list comprehension, filled with random values, size 10000\n1.29 ms ± 16 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\nGenerating via numpy.array(), filled with random values, size 10000\n68 µs ± 664 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
    }
   ],
   "source": [
    "print('Generating via naive for loop, filled with random values, size', ARRAY_SIZE)\n",
    "%timeit generate_rand_naive()\n",
    "print('Generating via list comprehension, filled with random values, size', ARRAY_SIZE)\n",
    "%timeit generate_rand_compr()\n",
    "print('Generating via numpy.array(), filled with random values, size', ARRAY_SIZE)\n",
    "%timeit generate_rand_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_naive(arr):\n",
    "    tot = 0\n",
    "    for el in arr:\n",
    "        tot += el\n",
    "    return tot\n",
    "\n",
    "def sum_compr(arr):\n",
    "    return sum(arr)\n",
    "\n",
    "def sum_numpy(arr):\n",
    "    return np.sum(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Summing via naive for loop, size 10000\n445 µs ± 8.54 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\nSumming via built-in sum(), size 10000\n55.1 µs ± 583 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\nSumming via numpy.sum(), size 10000\n10.4 µs ± 1.29 µs per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
    }
   ],
   "source": [
    "print('Summing via naive for loop, size', ARRAY_SIZE)\n",
    "%timeit sum_naive(py_rand)\n",
    "print('Summing via built-in sum(), size', ARRAY_SIZE)\n",
    "%timeit sum_compr(py_rand)\n",
    "print('Summing via numpy.sum(), size', ARRAY_SIZE)\n",
    "%timeit sum_numpy(np_rand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_naive(arr):\n",
    "    tot = 0\n",
    "    cnt = 0\n",
    "    for el in arr:\n",
    "        tot += el\n",
    "        cnt += 1\n",
    "    return tot / cnt\n",
    "\n",
    "def avg_compr(arr):\n",
    "    tot = sum(arr)\n",
    "    cnt = len(arr)\n",
    "    return tot / cnt\n",
    "\n",
    "def avg_numpy(arr):\n",
    "    avg = np.mean(arr)\n",
    "    return avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Averaging via naive for loop, size 10000\n1.42 ms ± 23.9 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\nAveraging via built-in sum() and len(), size 10000\n54.5 µs ± 958 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\nAveraging via numpy.mean(), size 10000\n13.5 µs ± 115 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
    }
   ],
   "source": [
    "print('Averaging via naive for loop, size', ARRAY_SIZE)\n",
    "%timeit avg_naive(py_rand)\n",
    "print('Averaging via built-in sum() and len(), size', ARRAY_SIZE)\n",
    "%timeit avg_compr(py_rand)\n",
    "print('Averaging via numpy.mean(), size', ARRAY_SIZE)\n",
    "%timeit avg_numpy(np_rand)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis\n",
    "\n",
    "Below is a table summarizing the results (all arrays of size $10000$, times all in $\\mu s$):\n",
    "\n",
    "| task | naive | compr | `numpy` |\n",
    "| :- | -: | -: | -: |\n",
    "| generate array of 1s | $797 \\pm 8.54$ | $24.4 \\pm 0.493$ | $7.99 \\pm 0.158$ |\n",
    "| generate random array | $1960 \\pm 80.9$ | $1290 \\pm 16$ | $68 \\pm 0.664$ |\n",
    "| compute sum | $445 \\pm 8.54$ | $55.1 \\pm 0.583$ | $10.4 \\pm 1.29$ |\n",
    "| compute average | $1420 \\pm 23.9$ | $54.5 \\pm 0.958$ | $13.5 \\pm 0.115$ |\n",
    "\n",
    "Here, we can see that for almost all of the tasks, list comprehension is one order of magnitude faster than using naive `for` loops, and using `numpy` is one more order of magnitude faster than that. The only exception is the case of generating arrays filled with random values. Here, we see that list comprehension still offers a decent speed boost, well beyond what is statistically significant. The reason why list comprehension is slower here is that unlike the other three tasks, we cannot \"hide\" the for loop. If we were to try a similar method as generating an array of $1$s (e.g. `[random.random()] * size`), the resultant array will have the correct size, and the values will be random, but they will all be the same!\n",
    "\n",
    "Almost without exception, *implicit* for loops are faster than *explicit* ones (although in some cases, code readability may be more important). This is because Python's built-in functions are written using the C programming language, which is much more verbose (technical term here is \"strictly typed\"). The verbosity makes it __harder to play around with the data__, but makes the code __run much faster__, because the computer can apply a bunch of tricks specifically designed for the explicit type of data being used. Python is designed to be easy to write and experiment with, and for most tasks, it is fast __enough__ since the tasks don't get repeated thousands or millions of times. However, when the task does need to be repeated, Python offers alternative solutions that are optimized behind the scenes which makes the code go *zoom zoom*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing Non-trivial Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_naive(arr, lo, hi):\n",
    "    # simple implementation of the well-known quicksort\n",
    "    def swap(arr, i, j):\n",
    "        temp = arr[i]\n",
    "        arr[i] = arr[j]\n",
    "        arr[j] = temp\n",
    "    \n",
    "    def partition(arr, lo, hi):\n",
    "        pivot = arr[hi]\n",
    "        i = lo\n",
    "        for j in range(lo, hi):\n",
    "            if arr[j] < pivot:\n",
    "                swap(arr, i, j)\n",
    "                i += 1\n",
    "        swap(arr, i, hi)\n",
    "        return i\n",
    "    \n",
    "    if lo < hi:\n",
    "        p = partition(arr, lo, hi)\n",
    "        sort_naive(arr, lo, p-1)\n",
    "        sort_naive(arr, p+1, hi)\n",
    "\n",
    "def sort_compr(arr):\n",
    "    arr.sort() # note that this calls Python's built-in sort() function\n",
    "\n",
    "def sort_numpy(arr):\n",
    "    arr.sort() # note that this calls numpy's built-in sort() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Sorting via naive quicksort, size 10000\n58.5 ms ± 1.07 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\nSorting via built-in sort(), size 10000\n2.33 ms ± 100 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\nSorting via numpy.sort(), size 10000\n541 µs ± 6.53 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
    }
   ],
   "source": [
    "print('Sorting via naive quicksort, size', ARRAY_SIZE)\n",
    "%timeit sort_naive(generate_rand_naive(), 0, ARRAY_SIZE-1)\n",
    "print('Sorting via built-in sort(), size', ARRAY_SIZE)\n",
    "%timeit sort_compr(generate_rand_compr())\n",
    "print('Sorting via numpy.sort(), size', ARRAY_SIZE)\n",
    "%timeit sort_numpy(generate_rand_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def std_naive(arr):\n",
    "    avg = avg_naive(arr)\n",
    "    square_diff = 0\n",
    "    cnt = 0\n",
    "    for el in arr:\n",
    "        square_diff += (el - avg) ** 2\n",
    "        cnt += 1\n",
    "    return math.sqrt(square_diff / cnt)\n",
    "\n",
    "def std_compr(arr):\n",
    "    avg = avg_compr(arr)\n",
    "    square_diff = sum([(val - avg)**2 for val in arr])\n",
    "    return math.sqrt(square_diff / len(arr))\n",
    "\n",
    "def std_numpy(np_arr):\n",
    "    std = np.std(np_arr)\n",
    "    return std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Standard deviation via naive loop, size 10000\n4.03 ms ± 39.8 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\nStandard deviation via list comprehension, size 10000\n1.43 ms ± 17.9 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\nStandard deviation via np.std(), size 10000\n40.7 µs ± 544 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
    }
   ],
   "source": [
    "print('Standard deviation via naive loop, size', ARRAY_SIZE)\n",
    "%timeit std_naive(py_rand)\n",
    "print('Standard deviation via list comprehension, size', ARRAY_SIZE)\n",
    "%timeit std_compr(py_rand)\n",
    "print('Standard deviation via np.std(), size', ARRAY_SIZE)\n",
    "%timeit std_numpy(np_rand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sin_naive(arr):\n",
    "    sin_arr = []\n",
    "    for el in arr:\n",
    "        sin_arr.append(math.sin(el))\n",
    "    return sin_arr\n",
    "\n",
    "def sin_compr(arr):\n",
    "    sin_arr = list(map(math.sin, py_rand))\n",
    "    return sin_arr\n",
    "\n",
    "def sin_numpy(arr):\n",
    "    sin_arr = np.sin(arr)\n",
    "    return sin_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Trigonmetric sine via naive loop, size 10000\n2.14 ms ± 21 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\nTrigonmetric sine via built-in map(), size 10000\n770 µs ± 6.68 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\nTrigonmetric sine via np.sin(), size 10000\n129 µs ± 731 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
    }
   ],
   "source": [
    "print('Trigonmetric sine via naive loop, size', ARRAY_SIZE)\n",
    "%timeit sin_naive(py_rand)\n",
    "print('Trigonmetric sine via built-in map(), size', ARRAY_SIZE)\n",
    "%timeit sin_compr(py_rand)\n",
    "print('Trigonmetric sine via np.sin(), size', ARRAY_SIZE)\n",
    "%timeit sin_numpy(np_rand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp_naive(arr):\n",
    "    exp_arr = []\n",
    "    for el in arr:\n",
    "        exp_arr.append(math.e ** el)\n",
    "    return exp_arr\n",
    "\n",
    "def exp_compr(arr):\n",
    "    # this is also more accurate!\n",
    "    exp_arr = list(map(math.exp, py_rand))\n",
    "    return exp_arr\n",
    "\n",
    "def exp_numpy(arr):\n",
    "    exp_arr = np.exp(arr)\n",
    "    return exp_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Exponential via naive loop, size 10000\n2.43 ms ± 13.1 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\nExponential via built-in map(), size 10000\n726 µs ± 3.5 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\nExponential via np.exp(), size 10000\n124 µs ± 2.27 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
    }
   ],
   "source": [
    "print('Exponential via naive loop, size', ARRAY_SIZE)\n",
    "%timeit exp_naive(py_rand)\n",
    "print('Exponential via built-in map(), size', ARRAY_SIZE)\n",
    "%timeit exp_compr(py_rand)\n",
    "print('Exponential via np.exp(), size', ARRAY_SIZE)\n",
    "%timeit exp_numpy(np_rand)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis\n",
    "\n",
    "Below is the table summary for this section (array size is 10000, time units in $\\mu s$):\n",
    "\n",
    "| task | naive | compr | `numpy` |\n",
    "| :- | -: | -: | -: |\n",
    "| sort (raw) | $5850 \\pm 1070$ | $2330 \\pm 100$ | $541 \\pm 6.53$ |\n",
    "| sort (clean) | $3890 \\pm 1150$ | $1040 \\pm 120$ | $473 \\pm 7.18$ |\n",
    "| std. dev. | $4030 \\pm 39.8$ | $1430 \\pm 17.9$ | $40.7 \\pm 0.544$ |\n",
    "| sin(x) | $2140 \\pm 21.0$ | $770 \\pm 6.68$ | $129 \\pm 0.731$ |\n",
    "| exp(x) | $2430 \\pm 13.1$ | $726 \\pm 3.50$ | $124 \\pm 2.27$ |\n",
    "\n",
    "Here, we see again that `numpy` is 100 times faster than the naive approach. However, we see that list comprehension is no longer a 10x improvement over the naive approach, and is instead close to only 3 times faster. This is primarily because these complicated functions require more individual computations (e.g. Taylor expansions), and the difference between `numpy` and the built-in functions adds up.\n",
    "\n",
    "For the sorting task, I ran the sorting algorithm on a new, randomly generated array every single time to average out the strengths and weaknesses of various sorting algorithms. The \"raw\" row shows the total time measured, while the \"clean\" row excludes the time needed to run the random generation, as measured in the previous section. Note that for this task, the built-in function performs very well when compared to `numpy`; this is because the same sorting algorithm is used, and the only hidden function being run is the comparison function (i.e. is element A smaller than element B?), which gives us the opposite result compared to the other three functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manipulating Multiple Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "py_secn = generate_rand_compr()\n",
    "np_secn = np.array(py_secn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_mult_naive(arr1, arr2):\n",
    "    sum_arr = []\n",
    "    for i in range(len(arr1)):\n",
    "        sum_arr.append(arr1[i] + arr2[i])\n",
    "    return sum_arr\n",
    "\n",
    "def sum_mult_compr(arr1, arr2):\n",
    "    sum_arr = list(map(operator.add, arr1, arr2))\n",
    "    return sum_arr\n",
    "    # sum_arr = [a1 + a2 for a1, a2 in zip(arr1, arr2)]\n",
    "    # while the above line is okay, it's actually about twice as slow as the other one\n",
    "\n",
    "def sum_mult_numpy(arr1, arr2):\n",
    "    sum_arr = np.add(arr1, arr2) # can also use arr1 + arr2\n",
    "    return sum_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Sum of two python lists via naive for loop, size 10000\n1.59 ms ± 52.7 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\nSum of two python lists via built-in map(), size 10000\n414 µs ± 5.82 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\nSum of two numpy arrays via np.add(), size 10000\n5.05 µs ± 27.2 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
    }
   ],
   "source": [
    "print('Sum of two python lists via naive for loop, size', ARRAY_SIZE)\n",
    "%timeit sum_mult_naive(py_rand, py_secn)\n",
    "print('Sum of two python lists via built-in map(), size', ARRAY_SIZE)\n",
    "%timeit sum_mult_compr(py_rand, py_secn)\n",
    "print('Sum of two numpy arrays via np.add(), size', ARRAY_SIZE)\n",
    "%timeit sum_mult_numpy(np_rand, np_secn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prod_mult_naive(arr1, arr2):\n",
    "    prod_arr = []\n",
    "    for i in range(len(arr1)):\n",
    "        prod_arr.append(arr1[i] * arr2[i])\n",
    "    return prod_arr\n",
    "\n",
    "def prod_mult_compr(arr1, arr2):\n",
    "    prod_arr = list(map(operator.mul, arr1, arr2))\n",
    "    return prod_arr\n",
    "    # prod_arr = [a1 * a2 for a1, a2 in zip(arr1, arr2)]\n",
    "\n",
    "def prod_mult_numpy(arr1, arr2):\n",
    "    prod_arr = np.multiply(arr1, arr2) # can also use arr1 * arr2\n",
    "    return prod_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Product of two python lists via naive for loop, size 10000\n1.56 ms ± 17.3 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\nProduct of two python lists via built-in map(), size 10000\n433 µs ± 2.57 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\nProduct of two numpy arrays via np.multiply(), size 10000\n5.12 µs ± 111 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
    }
   ],
   "source": [
    "print('Product of two python lists via naive for loop, size', ARRAY_SIZE)\n",
    "%timeit prod_mult_naive(py_rand, py_secn)\n",
    "print('Product of two python lists via built-in map(), size', ARRAY_SIZE)\n",
    "%timeit prod_mult_compr(py_rand, py_secn)\n",
    "print('Product of two numpy arrays via np.multiply(), size', ARRAY_SIZE)\n",
    "%timeit prod_mult_numpy(np_rand, np_secn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dot_prod_naive(arr1, arr2):\n",
    "    dp = 0\n",
    "    for i in range(len(arr1)):\n",
    "        dp += arr1[i] * arr2[i]\n",
    "    return dp\n",
    "\n",
    "def dot_prod_compr(arr1, arr2):\n",
    "    dp = sum(map(operator.mul, arr1, arr2))\n",
    "    return dp\n",
    "\n",
    "def dot_prod_numpy(arr1, arr2):\n",
    "    dp = np.dot(arr1, arr2)\n",
    "    return dp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Dot product of two python lists via naive for loop, size 10000\n1.74 ms ± 62.7 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\nDot product of two python lists via built-in map(), size 10000\n442 µs ± 15.8 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\nDot product of two numpy arrays via numpy.dot(), size 10000\n5.46 µs ± 78 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
    }
   ],
   "source": [
    "print('Dot product of two python lists via naive for loop, size', ARRAY_SIZE)\n",
    "%timeit prod_mult_naive(py_rand, py_secn)\n",
    "print('Dot product of two python lists via built-in map(), size', ARRAY_SIZE)\n",
    "%timeit prod_mult_compr(py_rand, py_secn)\n",
    "print('Dot product of two numpy arrays via numpy.dot(), size', ARRAY_SIZE)\n",
    "%timeit prod_mult_numpy(np_rand, np_secn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis\n",
    "One more table, array size is 10000, times in $\\mu s$:\n",
    "\n",
    "| task | naive | compr | `numpy` |\n",
    "| :- | -: | -: | -: |\n",
    "| element-wise sum | $1590 \\pm 52.7$ | $414 \\pm 5.82$ | $5.05 \\pm 0.027$ |\n",
    "| element-wise prod | $1560 \\pm 17.3$ | $433 \\pm 2.57$ | $5.12 \\pm 0.111$ |\n",
    "| dot product | $1740 \\pm 62.7$ | $442 \\pm 15.8$ | $5.46 \\pm 0.078$ |\n",
    "\n",
    "Here, we see that `numpy` performs a whopping *300 times* faster than the basic for loop, and almost 100 times better than list comprehension. This shows where `numpy` really starts to shine: with multiple arrays and multi-dimensional arrays. The reason for this is discussed in the appendix, but the general gist is that `numpy` stores its arrays inside the computer memory differently from how Python handles lists. This reflects the differences in design philosophies (as discussed earlier), but the best part is that using Python and its plethora of libraries, you are able to get the best of both worlds.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix\n",
    "Many useful libraries such as `pandas`, `scipy`, and `scikit-learn` use `numpy` arrays behind the scenes, because it performs so well. One way to check if a particular method uses `numpy` is by checking the type of the result, likeso:\n",
    "\n",
    "```\n",
    "result = useful_module.cool_function()\n",
    "print(type(result))\n",
    ">>> numpy.ndarray\n",
    "```\n",
    "\n",
    "If you see `numpy.ndarray` or something similar, this function probably uses `numpy` in the background.\n",
    "\n",
    "Note that `numpy` is very finicky about its data types, and more often than not, putting things that aren't numbers into the arrays will cause `numpy` to be unhappy.\n",
    "\n",
    "** \\*\\* warning for technical details \\*\\* **\n",
    "\n",
    "This is particularly true of Python __objects__, which actually remove one of the core advantages of `numpy`, namely *contiguous memory*. One of the reasons why `numpy` is written in C is the power of working with computer memory directly, and *pointer arithmetic* (which allows code to grab data from arbitrary locations in memory). `numpy` takes advantage of this by storing each array's data in continuous blocks of memory, which reduces both computation time and the memory footprint of the code. However, when Python objects are stored in a `numpy` array, the values inside the array are themselves pointers to the actual memory location of the object. This means that `numpy` is no longer able to use 90% of its fancy tricks, which in turn means that performance degrades *very quickly*.\n",
    "\n",
    "** \\*\\* end of technical details \\*\\* **\n",
    "\n",
    "Common examples of Python objects that get shoved into `numpy` arrays are `string`s, `list`s, and `tuple`s. If you check the array's data type (use `arr.dtype`) and find that the array is treating your data as objects, try changing the `dtype` property when you initialize the array, or check the documentation for the correct method to store the data format.\n",
    "\n",
    "However, in the **worst case scenario**, `numpy`'s performance is no worse than using Python lists, which means that you should always use `numpy` arrays over Python lists, whenever possible. Just check to make sure that you're getting the most out of `numpy`'s functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}